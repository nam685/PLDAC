{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKwxrNgYOZAw"
   },
   "source": [
    "# Recherche d'information : librairie PyTerrier\n",
    "\n",
    "Dans cette partie, nous nous intéressons à la librairie [PyTerrier](https://pyterrier.readthedocs.io/en/latest/#) qui permet de mettre en place diverses briques d'un moteur de recherche.\n",
    "PyTerrier est basée sur [Terrier](http://terrier.org/) qui est un moteur de recherche développé en Java.\n",
    "\n",
    "Nous allons voir : \n",
    "*   l'installation et la configuration\n",
    "*   l'indexation d'une collection\n",
    "*   l'accès à l'index\n",
    "*   l'évaluation d'un moteur de recherche\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwuWey_dPRa5"
   },
   "source": [
    "## Installation ete configuration\n",
    "\n",
    "Après l'installation de la librairie, il est nécessaire d'initialiser PyTerrier pour importer les fichiers jar et démarrer la machine virtuelle associée; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19312,
     "status": "ok",
     "timestamp": 1623930696718,
     "user": {
      "displayName": "Lau re",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzuUia-j0jYugKgvO36IkfRFcUwM6qoXOYimquhg=s64",
      "userId": "03302099944040145915"
     },
     "user_tz": -120
    },
    "id": "6BVCdIzcOCkc",
    "outputId": "bbddcf18-7795-4d4c-aca9-ed0f6105ca18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting python-terrier\n",
      "  Downloading python-terrier-0.8.0.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 5.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.19.0)\n",
      "Requirement already satisfied: pandas in /users/nfs/Etu7/28613397/.local/lib/python3.7/site-packages (from python-terrier) (1.3.4)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Requirement already satisfied: tqdm in /users/nfs/Etu7/28613397/.local/lib/python3.7/site-packages (from python-terrier) (4.62.3)\n",
      "Collecting pyjnius~=1.3.0\n",
      "  Downloading pyjnius-1.3.0-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 61.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matchpy\n",
      "  Downloading matchpy-0.5.5-py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 7.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.0)\n",
      "Collecting deprecation\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting chest\n",
      "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from python-terrier) (1.4.1)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from python-terrier) (2.21.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from python-terrier) (0.16.0)\n",
      "Collecting nptyping\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
      "Collecting more_itertools\n",
      "  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ir_datasets>=0.3.2\n",
      "  Downloading ir_datasets-0.5.0-py3-none-any.whl (255 kB)\n",
      "\u001b[K     |████████████████████████████████| 255 kB 40.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from python-terrier) (2.11.2)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 25.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ir_measures>=0.2.0\n",
      "  Downloading ir_measures-0.2.3.tar.gz (41 kB)\n",
      "\u001b[K     |████████████████████████████████| 41 kB 256 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->python-terrier) (2020.1)\n",
      "Requirement already satisfied: six>=1.7.0 in /usr/lib/python3/dist-packages (from pyjnius~=1.3.0->python-terrier) (1.12.0)\n",
      "Collecting cython\n",
      "  Downloading Cython-0.29.27-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 41.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multiset<3.0,>=2.0\n",
      "  Downloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->python-terrier) (0.23.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation->python-terrier) (20.4)\n",
      "Collecting heapdict\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Collecting typish>=1.7.0\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 2.8 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting zlib-state>=0.1.3\n",
      "  Downloading zlib_state-0.1.5-cp37-cp37m-manylinux2010_x86_64.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 1.6 MB/s  eta 0:00:011\n",
      "\u001b[?25hCollecting pyautocorpus>=0.1.1\n",
      "  Downloading pyautocorpus-0.1.8-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 42.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets>=0.3.2->python-terrier) (5.3.1)\n",
      "Collecting ijson>=3.1.3\n",
      "  Downloading ijson-3.1.4-cp37-cp37m-manylinux2010_x86_64.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 66.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting lz4>=3.1.1\n",
      "  Downloading lz4-3.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8 MB 32.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting warc3-wet>=0.2.3\n",
      "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.9.1)\n",
      "Collecting lxml>=4.5.2\n",
      "  Downloading lxml-4.7.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.4 MB 68.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting warc3-wet-clueweb09>=0.2.5\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "Collecting trec-car-tools>=2.5.4\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/lib/python3/dist-packages (from jinja2->python-terrier) (1.1.0)\n",
      "Collecting patsy>=0.5.2\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 32.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytrec-eval-terrier==0.5.1\n",
      "  Downloading pytrec_eval_terrier-0.5.1-cp37-cp37m-manylinux2010_x86_64.whl (291 kB)\n",
      "\u001b[K     |████████████████████████████████| 291 kB 52.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cwl-eval>=1.0.10\n",
      "  Downloading cwl-eval-1.0.10.tar.gz (31 kB)\n",
      "Collecting pyndeval>=0.0.2\n",
      "  Downloading pyndeval-0.0.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (59 kB)\n",
      "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->python-terrier) (2.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->deprecation->python-terrier) (2.4.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.7/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets>=0.3.2->python-terrier) (2.0.1)\n",
      "Collecting cbor>=1.0.0\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "Building wheels for collected packages: python-terrier, wget, chest, ir-measures, warc3-wet-clueweb09, cwl-eval, cbor\n",
      "  Building wheel for python-terrier (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for python-terrier: filename=python_terrier-0.8.0-py3-none-any.whl size=103875 sha256=9020f2fbebcae135f7ab4b1c5a04c492758363bda6c2c8a60a0e3fef13efd80a\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/a8/ec/0c/fd9fcb409ad158d1f62534f9b1924b406f420f1a4170fb4132\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9679 sha256=1cb09e4be894ea98013affb06779c1986a9e57c4407cae7eebd8f83e85d62912\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
      "  Building wheel for chest (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7623 sha256=0fed7a0f6c7bb7d12f96c1dd2ed1b4355f4f841c56e87fbcb47ad2a7db58b265\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/fc/f5/b9/c436e11300809e6b40d46a5d2592fb0bff89e0712f2e878dc7\n",
      "  Building wheel for ir-measures (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ir-measures: filename=ir_measures-0.2.3-py3-none-any.whl size=53200 sha256=6d38f32d46d72f382553b30949aff864de4e2c6251b30b0e334566d700da9ba3\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/b2/06/1b/b8dc2d9a9802a9c30dd3a28d4199061297df0034d8ab9b808a\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18908 sha256=da1624a4aee162149075ae34232c55096abf1da17e4c28b9e44719c5ccc19adf\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/42/d4/3c/7c2b0c3d400ad744e4db69f2fde166655da2ed2198bfc02db6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for cwl-eval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cwl-eval: filename=cwl_eval-1.0.10-py3-none-any.whl size=37796 sha256=b9db89c50279c355dc86af2f09f1d59a42aa366a37fde5e261e4aa40233b343c\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/ff/e9/ff/d2b6d72d9feb0d0b1b11aacfaf5cd866717034615c2d194093\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cbor: filename=cbor-1.0.0-cp37-cp37m-linux_x86_64.whl size=55978 sha256=04c136645a60cb13114d27ab6e04ad34f9f4a3e58a8131497d7683f878fd2e32\n",
      "  Stored in directory: /users/nfs/Etu7/28613397/.cache/pip/wheels/19/77/49/c9c2c8dc5848502e606e8579d0bbda18b850fb056a6c62239d\n",
      "Successfully built python-terrier wget chest ir-measures warc3-wet-clueweb09 cwl-eval cbor\n",
      "Installing collected packages: wget, cython, pyjnius, multiset, matchpy, deprecation, heapdict, chest, typish, nptyping, more-itertools, zlib-state, pyautocorpus, ijson, lz4, warc3-wet, lxml, warc3-wet-clueweb09, cbor, trec-car-tools, ir-datasets, patsy, statsmodels, pytrec-eval-terrier, cwl-eval, pyndeval, ir-measures, dill, python-terrier\n",
      "\u001b[33m  WARNING: The scripts cygdb, cython and cythonize are installed in '/users/Etu7/28613397/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script ir_datasets is installed in '/users/Etu7/28613397/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script ir_measures is installed in '/users/Etu7/28613397/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "ir-datasets 0.5.0 requires requests>=2.22.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
      "Successfully installed cbor-1.0.0 chest-0.2.3 cwl-eval-1.0.10 cython-0.29.27 deprecation-2.1.0 dill-0.3.4 heapdict-1.0.1 ijson-3.1.4 ir-datasets-0.5.0 ir-measures-0.2.3 lxml-4.7.1 lz4-3.1.10 matchpy-0.5.5 more-itertools-8.12.0 multiset-2.1.1 nptyping-1.4.4 patsy-0.5.2 pyautocorpus-0.1.8 pyjnius-1.3.0 pyndeval-0.0.2 python-terrier-0.8.0 pytrec-eval-terrier-0.5.1 statsmodels-0.13.1 trec-car-tools-2.6 typish-1.9.3 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 wget-3.2 zlib-state-0.1.5\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.3.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "terrier-assemblies 5.6 jar-with-dependencies not found, downloading to /users/Etu7/28613397/.pyterrier...\n",
      "Done\n",
      "terrier-python-helper 0.0.6 jar not found, downloading to /users/Etu7/28613397/.pyterrier...\n",
      "Done\n",
      "terrier-prf -SNAPSHOT jar not found, downloading to /users/Etu7/28613397/.pyterrier...\n",
      "Done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "(\"Pyterrier requires Java 11 or newer, we only found Java version %s; install a more recent Java, or change os.environ['JAVA_HOME'] to point to the proper Java installation\", '1.8.0_171')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3a0101e5fa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyterrier\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_packages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pyterrier/__init__.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(version, mem, packages, jvm_opts, redirect_io, logging, home_dir, boot_packages, tqdm, no_download, helper_version)\u001b[0m\n\u001b[1;32m    127\u001b[0m         raise RuntimeError(\"Pyterrier requires Java 11 or newer, we only found Java version %s;\"\n\u001b[1;32m    128\u001b[0m             \u001b[0;34m+\u001b[0m\u001b[0;34m\" install a more recent Java, or change os.environ['JAVA_HOME'] to point to the proper Java installation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             java_version)\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mtr_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.terrier.Version'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: (\"Pyterrier requires Java 11 or newer, we only found Java version %s; install a more recent Java, or change os.environ['JAVA_HOME'] to point to the proper Java installation\", '1.8.0_171')"
     ]
    }
   ],
   "source": [
    "!pip install python-terrier\n",
    "\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "  pt.init(boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOC7UxlTP1IP"
   },
   "source": [
    "## Indexation d'une collection\n",
    "\n",
    "Il est possible d'indexer plusieurs formats de collection : format TREC, fichiers en texte brut ou en PDF, ou encore des Dataframe Pandas ([pour plus de détails](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html)).\n",
    "\n",
    "Un petit exemple à titre illustratif est foourni dans le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1623930698050,
     "user": {
      "displayName": "Lau re",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzuUia-j0jYugKgvO36IkfRFcUwM6qoXOYimquhg=s64",
      "userId": "03302099944040145915"
     },
     "user_tz": -120
    },
    "id": "sv9pe_KePd3e",
    "outputId": "9176a7c3-7409-4476-b404-7e52840de40d"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyterrier' has no attribute 'DFIndexer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fe7723da0ba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# création de l'index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDFIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./index_3docs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Définition du format de données (DFIndexer())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mindex_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"docno\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Indexation des champs text et docno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -lh index_3docs/                                            # Affichage de l\\'index sauvegardé dans \"./index_3docs/\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyterrier' has no attribute 'DFIndexer'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# configuration de l'affichage\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "# le jeu de données au format DataFrame\n",
    "docs_df = pd.DataFrame([\n",
    "        [\"d1\", \"this is the first document of many documents\"],\n",
    "        [\"d2\", \"this is another document\"],\n",
    "        [\"d3\", \"the topic of this document is unknown\"]\n",
    "    ], columns=[\"docno\", \"text\"])\n",
    "\n",
    "# création de l'index\n",
    "indexer = pt.DFIndexer(\"./index_3docs\", overwrite=True)         # Définition du format de données (DFIndexer())\n",
    "index_ref = indexer.index(docs_df[\"text\"], docs_df[\"docno\"])    # Indexation des champs text et docno\n",
    "!ls -lh index_3docs/                                            # Affichage de l'index sauvegardé dans \"./index_3docs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tajl4sILR3J0"
   },
   "source": [
    "De nombreux fichiers sont créés : index direct, index inverse, méta-données de l'index et de la configuration de l'indexation, etc...\n",
    "\n",
    "\n",
    "Il est également possible de modifier la configuration de l'indexation : [voir ici](https://pyterrier.readthedocs.io/en/latest/terrier-indexing.html#indexing-configuration).\n",
    "\n",
    "Pour chager un index existant en local :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayENptR-TO4j"
   },
   "outputs": [],
   "source": [
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd56Q1LgTI2_"
   },
   "source": [
    "Il est aussi possible de voir les statistiques de l'index. \n",
    "pour connaître toutes les fonctions d'interrogation, se référencer à la [javadoc](http://terrier.org/docs/current/javadoc/org/terrier/structures/Index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQAm27NnTtRj"
   },
   "outputs": [],
   "source": [
    "# statistiques de la collection\n",
    "print(index.getCollectionStatistics().toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uGk9z47PTx3E"
   },
   "outputs": [],
   "source": [
    "# statistiques du vocabulaire.\n",
    "# Nt : document frequency : nombre de documents contenant le terme\n",
    "# TF : term frequency : nombre d'occurences du terme\n",
    "# maxTF : nombre d'occurences maximal pour un document\n",
    "for kv in index.getLexicon():\n",
    "  print(\"%s (%s) -> %s (%s)\" % (kv.getKey(), type(kv.getKey()), kv.getValue().toString(), type(kv.getValue()) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dq-9yKHnUyRZ"
   },
   "outputs": [],
   "source": [
    "# focus sur un terme particulier\n",
    "index.getLexicon()[\"document\"].toString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MTLZHWKWU78h"
   },
   "outputs": [],
   "source": [
    "# récupère les statistiques de l'index inverse à partir d'un terme particulier\n",
    "pointer = index.getLexicon()[\"document\"]\n",
    "for posting in index.getInvertedIndex().getPostings(pointer):\n",
    "    print(posting.toString() + \" doclen=%d\" % posting.getDocumentLength())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRXFRasZQ_xT"
   },
   "source": [
    "\n",
    "De plus, PyTerrier met à disposition [une collection de jeux de données pré-traités](https://pyterrier.readthedocs.io/en/latest/datasets.html).\n",
    "Dans ce qui suit, nous allons nous concentrer sur le jeu de données CORD19 qui recense des articles liés à la crise sanitaire Covid-19. Il est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqeBM8jBRAdX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "cord19 = pt.datasets.get_dataset('irds:cord19/trec-covid')\n",
    "pt_index_path = './terrier_cord19'\n",
    "\n",
    "if not os.path.exists(pt_index_path + \"/data.properties\"):\n",
    "  # création de l'index. Utilisation de l'itérateur pour parcourir la collection\n",
    "  indexer = pt.index.IterDictIndexer(pt_index_path)\n",
    "\n",
    "  # on donne à l'index la fonction pour parcourir l'index avec l'itérateur  get_corpus_iter() \n",
    "  # On spécifie les champs à indexer et les meta-données à sauvegarder\n",
    "  index_ref = indexer.index(cord19.get_corpus_iter(), \n",
    "                            fields=('abstract',), \n",
    "                            meta=('docno',))\n",
    "\n",
    "else:\n",
    "  # dans le cas où l'index existe déjà\n",
    "  index_ref = pt.IndexRef.of(pt_index_path + \"/data.properties\")\n",
    "index = pt.IndexFactory.of(index_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MMJ1_O1LV6Uf"
   },
   "source": [
    "**Exercice 1**\n",
    "\n",
    "Afficher les statistiques de l'index Cord19 et analyser statistiques du terme \"tv\" (pas trop fréquent pour question d'affichage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3MITxC-V3io"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTweZ9B4XD96"
   },
   "source": [
    "## Recherche de documents à partir de l'index\n",
    "\n",
    "Pour effectuer une recherche dans l'index, il faut utiliser la fonction batchRetrieve qui prend en paramètre l'index et le modèle de pondération (tf, tf-idf, etc...). La liste des modèles supportés est disponible [ici](http://terrier.org/docs/current/javadoc/org/terrier/matching/models/package-summary.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kKhE4BjWV9L"
   },
   "outputs": [],
   "source": [
    "br = pt.BatchRetrieve(index, wmodel=\"Tf\")\n",
    "br.search(\"chemical reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWGGSR4AXjfq"
   },
   "source": [
    "On récupère alors un DataFrame dont les colonnes sont les suivantes : \n",
    "*   qid : identifiant de la requête. Par défaut, il s'agit de \"1\", puisqu'il s'agit de notre première et unique requête.\n",
    "*   docid : l'identifiant interne de Terrier pour chaque document\n",
    "*   docno : l'identifiant unique externe (chaîne de caractères) pour chaque document\n",
    "*   score : score des documents selon le modèle choisi (ici : fréquence totale des tf des termes de la requête dans chaque document)\n",
    "*   rank : rang du document dénotant l'ordre décroissant par score.\n",
    "*   query : la requête d'entrée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QtXY5KnRZWe9"
   },
   "outputs": [],
   "source": [
    "# autre exemple de modèle : TF-IDF\n",
    "tfidf = pt.BatchRetrieve(index, wmodel=\"TF_IDF\")\n",
    "tfidf.search(\"chemical reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8vyslA7Yfa7"
   },
   "source": [
    "On peut aussi fournir plusieurs requêtes grâce à un dataFrame. Pour interroger l'index, on applique la fonction transform() au BatchRetriever (br).\n",
    "pour plus de détails, voir [les propriétés des transformations](https://pyterrier.readthedocs.io/en/latest/transformer.html) ainsi que les [opérations possibles](https://pyterrier.readthedocs.io/en/latest/operators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WewrczrCXA6X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "queries = pd.DataFrame([[\"q1\", \"document\"], [\"q2\", \"first document\"]], columns=[\"qid\", \"query\"])\n",
    "br.transform(queries)       # ou aussi : br(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEhSdCsqcycE"
   },
   "source": [
    "**Exercice 2**\n",
    "\n",
    "Ordonnancer les documents pour 3 requêtes : \"covid disease\", \"hospital\" et \"home\".\n",
    "La fonction d'ordonnacement devra être de la forme suivante : \n",
    "\n",
    "\n",
    "```\n",
    "0.4 * score_Bm25 + 0.6 * score_Dirichlet\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXSjd9iNeF56"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvnkNzOZrC4m"
   },
   "source": [
    "**Excercice 3**\n",
    "\n",
    "Créez un ordonnanceur qui effectue les opérations suivantes :\n",
    "* obtient les 10 documents les mieux notés par fréquence de terme (wmodel=\"Tf\")\n",
    "* obtenir les 10 documents les mieux notés par TF.IDF (wmodel=\"TF_IDF\")\n",
    "* ré-ordonne uniquement les documents trouvés dans les DEUX paramètres de recherche précédents en utilisant BM25.\n",
    "\n",
    "Combien de documents sont récupérés par ce pipeline complet pour la requête \"chemical\"?\n",
    "\n",
    "Vérification : le document avec le docno \"37771\" devrait avoir un score de 12.426309 $ pour la requête \"chemical\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_mSvL3qrkZd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raxeMrjrtSZh"
   },
   "source": [
    "## Reformulation de requêtes \n",
    "\n",
    "Il est également possible de mettre en place des pipelines de [reformulation de requêtes](https://pyterrier.readthedocs.io/en/latest/rewrite.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNSsCc-btYF2"
   },
   "outputs": [],
   "source": [
    "bo1 = pt.rewrite.Bo1QueryExpansion(index)\n",
    "dph = pt.BatchRetrieve(index, wmodel=\"DPH\")\n",
    "pipeline = dph >> bo1 >> dph\n",
    "pipeline.search(\"chemical reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC3oUh3qumUc"
   },
   "source": [
    "L'autre solution est de l'intégrer directement dans la fonction d'ordonnancement. Mais la requête reformulée n'est pas visible et la solution précédente fait prendre conscience de la pipeline faite par le système de RI (ranking >> reformulation >> ranking quand on utilise des modèles basés sur la relevance feedback. ou reformulation >> ranking sinon). Plus d'exemples [ici](https://pyterrier.readthedocs.io/en/latest/rewrite.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbBSKWzctufW"
   },
   "outputs": [],
   "source": [
    "# modèle DPH avant reformulation de requête\n",
    "pipelineQE = pt.BatchRetrieve(index, wmodel=\"DPH\", controls={\"qemodel\" : \"Bo1\", \"qe\" : \"off\"})\n",
    "pipelineQE.search(\"chemical reactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gjNvZw4GuHIN"
   },
   "outputs": [],
   "source": [
    "# modèle DPH après reformulation de requête\n",
    "pipelineQE = pt.BatchRetrieve(index, wmodel=\"DPH\", controls={\"qemodel\" : \"Bo1\", \"qe\" : \"on\"})\n",
    "pipelineQE.search(\"chemical reactions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KUOCsIKZ-tK"
   },
   "source": [
    "### Evaluation d'un système de recherche d'information\n",
    "\n",
    "Pour évaluer un système de RI, il est nécessaire d'avoir un jeu de données constitué de requêtes et de jugements de pertinence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAXFBHTIYeP4"
   },
   "outputs": [],
   "source": [
    "# exemple de 5 requêtes pour cord19\n",
    "cord19.get_topics(variant='title').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJN_uHkYaDea"
   },
   "outputs": [],
   "source": [
    "# exemple de jugements de pertinence pour les 5 premières requêtes\n",
    "cord19.get_qrels().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "em-jlm-Kaxpg"
   },
   "source": [
    "**Exercice 4**\n",
    "\n",
    "A partir des requêtes et des jugements de pertinence du jeu de données CORD19, Ecrire le code qui permet d'afficher les résultats de la première requête de Cord19. L'affichage fusionnera les colonnes retournées par le BatchRetriever et les colonnes des qrels (merge sur qid et docno pour rajouter label et iteration au tableau). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcf-geD1aGHY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qhx3qIFxb0_F"
   },
   "source": [
    "Il existe cependant une fonction qui permet de calculer l'efficacité de ces ordonnancements au travers des métriques d'évaluation (map, précision, rappel, ndcg, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "executionInfo": {
     "elapsed": 2537,
     "status": "ok",
     "timestamp": 1622974775467,
     "user": {
      "displayName": "Lau re",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgzuUia-j0jYugKgvO36IkfRFcUwM6qoXOYimquhg=s64",
      "userId": "03302099944040145915"
     },
     "user_tz": -120
    },
    "id": "l8W698iMavle",
    "outputId": "7b6a4a0e-00cd-4f65-e489-63c9a7e9d79d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>map</th>\n",
       "      <th>ndcg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BR(TF_IDF)</td>\n",
       "      <td>0.180008</td>\n",
       "      <td>0.370795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name       map      ndcg\n",
       "0  BR(TF_IDF)  0.180008  0.370795"
      ]
     },
     "execution_count": 99,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [tfidf],\n",
    "    cord19.get_topics(variant='title'),\n",
    "    cord19.get_qrels(),\n",
    "    eval_metrics=[\"map\", \"ndcg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUhh3BHyvaZD"
   },
   "source": [
    "**Exercice 5**\n",
    "\n",
    "Réaliser une expérience comparant l'expansion de requêtes avec le modèle Bo1 et basé sur la KL-divergence; L'expérience est réalisée sur TREC CORD19 avec le modèle de référence BM25. Vous devrez construire des pipelines appropriées (plus de détails sur [l'expansion](https://pyterrier.readthedocs.io/en/latest/rewrite.html) et les [expérimentations](https://pyterrier.readthedocs.io/en/latest/experiments.html)).\n",
    "\n",
    "Quelles approches entraînent des augmentations significatives de NDCG et MAP ou autres métriques ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cwyl1WBccB2U"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOIzPalboxK2rSLd+JuLCC2",
   "collapsed_sections": [],
   "name": "2021-RI-pyterrier-1-etal2021-etud.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
