{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finetune T5 CQR.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPjK45aiEIqS6HB+8P1lCWM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RdQxAbZ-jYnJ","executionInfo":{"status":"ok","timestamp":1645988558862,"user_tz":-60,"elapsed":1967,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"4c22c457-66e6-480b-80b6-a53738753ae6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/MyDrive/PLDAC\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/MyDrive/PLDAC/"]},{"cell_type":"code","source":["!pip install transformers -q\n","!pip install wandb -q\n","!pip install sentencepiece -q\n","# memory footprint support libraries/code\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip install gputil\n","!pip install psutil\n","!pip install humanize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsHzBJfQjpHC","executionInfo":{"status":"ok","timestamp":1645988581248,"user_tz":-60,"elapsed":22396,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"c5044108-26f5-4692-90b3-d5dc138547de"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gputil in /usr/local/lib/python3.7/dist-packages (1.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n","Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n"]}]},{"cell_type":"code","source":["# Importing stock libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import torch\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","# Importing the T5 modules from huggingface/transformers\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","\n","# WandB – Import the wandb library\n","import wandb\n","\n","from torch import cuda\n","\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU"],"metadata":{"id":"aiqh9uOtkP_S","executionInfo":{"status":"ok","timestamp":1645988583494,"user_tz":-60,"elapsed":2276,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Df0gL6pTlNWC","executionInfo":{"status":"ok","timestamp":1645988583497,"user_tz":-60,"elapsed":56,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"979b3272-5586-4f83-8ba4-4206fdcebe94"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Feb 27 19:03:03 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","source":["device = 'cuda' if cuda.is_available() else 'cpu'"],"metadata":{"id":"dkavBkO4let0","executionInfo":{"status":"ok","timestamp":1645988583504,"user_tz":-60,"elapsed":41,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!wandb login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2daoWX6lhxD","executionInfo":{"status":"ok","timestamp":1645988585866,"user_tz":-60,"elapsed":2400,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"ba5ddd80-d8b9-4f69-a2bf-8cf147a02d3c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnam685\u001b[0m (use `wandb login --relogin` to force relogin)\n"]}]},{"cell_type":"code","source":["def read_canard(type):\n","    '''\n","        type 0: all queries, all answers\n","        type 1: all queries, last 3 answers\n","        type 2: all queries, last 1 answers\n","        type 3: all queries, no answer\n","    '''\n","    canard_path = \"/content/gdrive/MyDrive/PLDAC/data/canard\"\n","    TYPES = [\"_all_all\",\"_all_3\",\"_all_1\",\"_all_0\"]\n","    train = pd.read_csv(f\"{canard_path}/train{TYPES[type]}.csv\")\n","    dev = pd.read_csv(f\"{canard_path}/dev{TYPES[type]}.csv\")\n","    test = pd.read_csv(f\"{canard_path}/test{TYPES[type]}.csv\")\n","    train = pd.concat([train,dev],ignore_index=True)\n","    return train, test # 35000 train 5000 test\n","\n","def read_trec(year,version,test_size=0.5):\n","    assert year==2020 or year==2021\n","    assert version in range(1,14)\n","    trec_path = \"/content/gdrive/MyDrive/PLDAC/data/treccast/treccastweb-master\"\n","    df = pd.read_csv(f\"{trec_path}/{year}/trec{year}_{version}.csv\")\n","    train, test = train_test_split(df, test_size=test_size,random_state=1)\n","    train = train.reset_index()\n","    test = test.reset_index()\n","    return train, test # about 240 train 240 test\n","\n","def createCQRdata(canard_type,trec_version):\n","    canard_train, canard_test = read_canard(canard_type)\n","    trec_train_2020, trec_test_2020 = read_trec(2020,trec_version)\n","    trec_train_2021, trec_test_2021 = read_trec(2021,trec_version)\n","    train = pd.concat([canard_train,trec_train_2020,trec_train_2021],ignore_index=True)\n","    val = pd.concat([canard_test,trec_test_2020,trec_test_2021], ignore_index=True)\n","    #train = train.sample(frac=1,random_state=1).reset_index(drop=True)\n","    #val = val.sample(frac=1,random_state=1).reset_index(drop=True)\n","    return train[[\"Source\",\"Target\"]], val[[\"Source\",\"Target\"]]"],"metadata":{"id":"NeypG12eF3Dd","executionInfo":{"status":"ok","timestamp":1645988634024,"user_tz":-60,"elapsed":205,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_tmp, val_tmp = createCQRdata(2,5)\n","plt.hist(train_tmp.Source.str.len())\n","plt.hist(train_tmp.Target.str.len())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"id":"8xBFzoKXA-fc","executionInfo":{"status":"ok","timestamp":1645988757930,"user_tz":-60,"elapsed":2873,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"c9fca45e-bff8-4f13-a5a0-7478c3abaf1a"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([1.1767e+04, 1.6196e+04, 5.2070e+03, 1.4790e+03, 3.6500e+02,\n","        1.2400e+02, 2.9000e+01, 1.1000e+01, 3.0000e+00, 2.0000e+00]),\n"," array([ 11. ,  43.7,  76.4, 109.1, 141.8, 174.5, 207.2, 239.9, 272.6,\n","        305.3, 338. ]),\n"," <a list of 10 Patch objects>)"]},"metadata":{},"execution_count":12},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["pd.DataFrame(train_tmp.Source[train_tmp.Source.str.len() > 800]).head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"LktIuysDV37X","executionInfo":{"status":"ok","timestamp":1645988770871,"user_tz":-60,"elapsed":256,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"a389ba25-ed19-4cdd-ade8-df31142a67ef"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-54f54002-86fb-47fe-b0c9-f3b4ce020275\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2688</th>\n","      <td>Query: Did they eventually bring down the apar...</td>\n","    </tr>\n","    <tr>\n","      <th>3448</th>\n","      <td>Query: Did the team celebrate after their winn...</td>\n","    </tr>\n","    <tr>\n","      <th>5465</th>\n","      <td>Query: What was Western Reserve? |||| Context:...</td>\n","    </tr>\n","    <tr>\n","      <th>8387</th>\n","      <td>Query: Were any family members involved with h...</td>\n","    </tr>\n","    <tr>\n","      <th>10633</th>\n","      <td>Query: Did the band tour outside of Australia?...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54f54002-86fb-47fe-b0c9-f3b4ce020275')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-54f54002-86fb-47fe-b0c9-f3b4ce020275 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-54f54002-86fb-47fe-b0c9-f3b4ce020275');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                  Source\n","2688   Query: Did they eventually bring down the apar...\n","3448   Query: Did the team celebrate after their winn...\n","5465   Query: What was Western Reserve? |||| Context:...\n","8387   Query: Were any family members involved with h...\n","10633  Query: Did the band tour outside of Australia?..."]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["from torch.utils.data.dataloader import default_collate\n","from torch.nn.utils.rnn import pad_sequence\n","\n","def my_collate(batch):\n","    padded_source_ids = pad_sequence([item['source_ids'] for item in batch], batch_first=True)\n","    padded_source_mask = pad_sequence([item['source_mask'] for item in batch], batch_first=True)\n","    padded_target_ids = pad_sequence([item['target_ids'] for item in batch], batch_first=True)\n","    batch = [{'source_ids':padded_source_ids[i], 'source_mask':padded_source_mask[i],\\\n","              'target_ids':padded_target_ids[i]} for i in range(len(padded_source_ids))]\n","    return default_collate(batch)"],"metadata":{"id":"a2cDhSl9HGl8","executionInfo":{"status":"ok","timestamp":1645988863997,"user_tz":-60,"elapsed":329,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n","\n","class CustomDataset(Dataset):\n","\n","    def __init__(self, dataframe, tokenizer, source_len, target_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.source_len = source_len\n","        self.target_len = target_len\n","        self.df_target = self.data.Target\n","        self.df_source = self.data.Source\n","\n","    def __len__(self):\n","        return len(self.df_target)\n","\n","    def __getitem__(self, index):\n","        df_source = str(self.df_source[index])\n","        df_source = ' '.join(df_source.split())\n","\n","        df_target = str(self.df_target[index])\n","        df_target = ' '.join(df_target.split())\n","\n","        source = self.tokenizer.batch_encode_plus([df_source], max_length= self.source_len, padding='longest',return_tensors='pt',truncation=True)\n","        target = self.tokenizer.batch_encode_plus([df_target], max_length= self.target_len, padding='longest',return_tensors='pt',truncation=True)\n","\n","        source_ids = source['input_ids'].squeeze()\n","        source_mask = source['attention_mask'].squeeze()\n","        target_ids = target['input_ids'].squeeze()\n","        target_mask = target['attention_mask'].squeeze()\n","\n","        return {\n","            'source_ids': source_ids.to(dtype=torch.long), \n","            'source_mask': source_mask.to(dtype=torch.long), \n","            'target_ids': target_ids.to(dtype=torch.long),\n","            #'target_ids_y': target_ids.to(dtype=torch.long)\n","        }"],"metadata":{"id":"5O8BOa7Gl7bQ","executionInfo":{"status":"ok","timestamp":1645988866430,"user_tz":-60,"elapsed":211,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Creating the training function. This will be called in the main function. It is run depending on the epoch value.\n","# The model is put into train mode and then we enumerate over the training loader and passed to the defined network \n","\n","def train(epoch, tokenizer, model, device, loader, optimizer):\n","    model.train()\n","    for _,data in enumerate(loader, 0):\n","        y = data['target_ids'].to(device, dtype = torch.long)\n","        y_ids = y[:, :-1].contiguous()\n","        labels = y[:, 1:].clone().detach()\n","        labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n","        ids = data['source_ids'].to(device, dtype = torch.long)\n","        mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=labels)\n","        loss = outputs[0]\n","        \n","        if _%10 == 0:\n","            wandb.log({\"Training Loss\": loss.item()})\n","\n","        if _%500==0:\n","            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()"],"metadata":{"id":"cMJ9wIORxYR0","executionInfo":{"status":"ok","timestamp":1645988870994,"user_tz":-60,"elapsed":260,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def validate(epoch, tokenizer, model, device, loader):\n","    model.eval()\n","    predictions = []\n","    actuals = []\n","    with torch.no_grad():\n","        for _, data in enumerate(loader, 0):\n","            y = data['target_ids'].to(device, dtype = torch.long)\n","            ids = data['source_ids'].to(device, dtype = torch.long)\n","            mask = data['source_mask'].to(device, dtype = torch.long)\n","\n","            generated_ids = model.generate(\n","                input_ids = ids,\n","                attention_mask = mask, \n","                max_length=250, \n","                num_beams=2,\n","                repetition_penalty=2.5, \n","                length_penalty=1.0, \n","                early_stopping=True\n","                )\n","            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n","            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n","            if _%100==0:\n","                print(f'Completed {_}')\n","\n","            predictions.extend(preds)\n","            actuals.extend(target)\n","    return predictions, actuals"],"metadata":{"id":"1KnUCn2hxYUe","executionInfo":{"status":"ok","timestamp":1645988871308,"user_tz":-60,"elapsed":8,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def main(canard_type,trec_version):\n","    # WandB – Initialize a new run\n","    wandb.init(project=\"conversational query reformulation\")\n","\n","    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n","    # Defining some key variables that will be used later on in the training  \n","    config = wandb.config          # Initialize config\n","    config.TRAIN_BATCH_SIZE = 8    # input batch size for training (default: 64)\n","    config.VALID_BATCH_SIZE = 8    # input batch size for testing (default: 1000)\n","    config.TRAIN_EPOCHS = 1        # number of epochs to train (default: 10)\n","    config.VAL_EPOCHS = 1 \n","    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n","    config.SEED = 42               # random seed (default: 42)\n","    config.MAX_LEN = 512\n","    config.TARGET_LEN = 256 \n","\n","    # Set random seeds and deterministic pytorch for reproducibility\n","    torch.manual_seed(config.SEED) # pytorch random seed\n","    np.random.seed(config.SEED) # numpy random seed\n","    torch.backends.cudnn.deterministic = True\n","\n","    # tokenizer for encoding the text\n","    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","    \n","    # Creation of Dataset and Dataloader\n","    train_dataset, val_dataset = createCQRdata(canard_type,trec_version)\n","\n","    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n","    print(\"TEST Dataset: {}\".format(val_dataset.shape))\n","\n","\n","    # Creating the Training and Validation dataset for further creation of Dataloader\n","    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.TARGET_LEN)\n","    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.TARGET_LEN)\n","\n","    # Defining the parameters for creation of dataloaders\n","    train_params = {\n","        'batch_size': config.TRAIN_BATCH_SIZE,\n","        'shuffle': True,\n","        'num_workers': 0,\n","        'collate_fn': my_collate\n","        }\n","\n","    val_params = {\n","        'batch_size': config.VALID_BATCH_SIZE,\n","        'shuffle': False,\n","        'num_workers': 0,\n","        'collate_fn': my_collate\n","        }\n","\n","    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n","    training_loader = DataLoader(training_set, **train_params)\n","    val_loader = DataLoader(val_set, **val_params)\n","\n","    \n","    # Defining the model. We are using t5-base model and added a Language model layer on top for generation. \n","    # Further this model is sent to device (GPU/TPU) for using the hardware.\n","    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n","    model = model.to(device)\n","\n","    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n","    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n","\n","    # Log metrics with wandb\n","    wandb.watch(model, log=\"all\")\n","    # Training loop\n","    printm()\n","    print('Initiating Fine-Tuning for the model on our dataset')\n","\n","    for epoch in range(config.TRAIN_EPOCHS):\n","        train(epoch, tokenizer, model, device, training_loader, optimizer)\n","\n","    # save model\n","    model.save_pretrained(save_directory=f\"./models/CQR/cqr{canard_type}{trec_version}\")\n","\n","    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n","    # Saving the dataframe as predictions.csv\n","    printm()\n","    print('Now generating reformulations on our fine tuned model for the validation dataset and saving it in a dataframe')\n","    for epoch in range(config.VAL_EPOCHS):\n","        predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n","        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n","        final_df.to_csv('./models/predictions.csv')\n","        print('Output Files generated for review')\n","    \n"],"metadata":{"id":"9MRxBRnIxYXb","executionInfo":{"status":"ok","timestamp":1645988873388,"user_tz":-60,"elapsed":202,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"-9uT2hi38Bx4","executionInfo":{"status":"ok","timestamp":1645988874882,"user_tz":-60,"elapsed":275,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n","    process = psutil.Process(os.getpid())\n","    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n","    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-xIXhPo2n1i","executionInfo":{"status":"ok","timestamp":1645988875821,"user_tz":-60,"elapsed":23,"user":{"displayName":"Nam Lê Hải","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04547901085605070272"}},"outputId":"bd6c4613-ed85-4ebf-ca62-81b86d52364b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Gen RAM Free: 11.5 GB  |     Proc size: 1.4 GB\n","GPU RAM Free: 11438MB | Used: 3MB | Util   0% | Total     11441MB\n"]}]},{"cell_type":"code","source":["main(2,5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"ednma2cO93jN","outputId":"6bcd75cf-3211-446a-db02-fb5d399f4270"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnam685\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/html":["\n","                    Syncing run <strong><a href=\"https://wandb.ai/nam685/conversational%20query%20reformulation/runs/2pwx6wnh\" target=\"_blank\">gallant-shape-23</a></strong> to <a href=\"https://wandb.ai/nam685/conversational%20query%20reformulation\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n","\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TRAIN Dataset: (35183, 2)\n","TEST Dataset: (5799, 2)\n","Gen RAM Free: 10.4 GB  |     Proc size: 5.0 GB\n","GPU RAM Free: 11438MB | Used: 3MB | Util   0% | Total     11441MB\n","Initiating Fine-Tuning for the model on our dataset\n","Epoch: 0, Loss:  7.292999267578125\n","Epoch: 0, Loss:  1.1825580596923828\n","Epoch: 0, Loss:  0.8917543888092041\n","Epoch: 0, Loss:  0.4397639334201813\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"5rjwvcWqOBQT"},"execution_count":null,"outputs":[]}]}